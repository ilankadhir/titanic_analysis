{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Titanic Analysis - Using Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the train data set and split it into train and validation sets.\n",
    "X = pd.read_csv(\"train.csv\")\n",
    "X_train, X_val = train_test_split(X, test_size = 0.2)\n",
    "\n",
    "y = X.pop(\"Survived\")\n",
    "y_train = X_train.pop('Survived')\n",
    "y_val = X_val.pop('Survived')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>714.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>2.308642</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0.523008</td>\n",
       "      <td>0.381594</td>\n",
       "      <td>32.204208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>257.353842</td>\n",
       "      <td>0.836071</td>\n",
       "      <td>14.526497</td>\n",
       "      <td>1.102743</td>\n",
       "      <td>0.806057</td>\n",
       "      <td>49.693429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>223.500000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>20.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.910400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.454200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>668.500000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>512.329200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       PassengerId      Pclass         Age       SibSp       Parch        Fare\n",
       "count   891.000000  891.000000  714.000000  891.000000  891.000000  891.000000\n",
       "mean    446.000000    2.308642   29.699118    0.523008    0.381594   32.204208\n",
       "std     257.353842    0.836071   14.526497    1.102743    0.806057   49.693429\n",
       "min       1.000000    1.000000    0.420000    0.000000    0.000000    0.000000\n",
       "25%     223.500000    2.000000   20.125000    0.000000    0.000000    7.910400\n",
       "50%     446.000000    3.000000   28.000000    0.000000    0.000000   14.454200\n",
       "75%     668.500000    3.000000   38.000000    1.000000    0.000000   31.000000\n",
       "max     891.000000    3.000000   80.000000    8.000000    6.000000  512.329200"
      ]
     },
     "execution_count": 494,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First, I'd like to attempt for a quick and dirty model using only the numerical columns. \n",
    "# Let's look at the quick summary of the numerical columns\n",
    "\n",
    "X.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exploring the numerical columns, I observed that Age has some missing values. \n",
    "# And to run the Random Forest Classifier, these null values need to be fixed.\n",
    "# I'm just imputing the null values with the mean values.\n",
    "\n",
    "X[\"Age\"].fillna(X_train['Age'].mean(), inplace=True)\n",
    "X_train[\"Age\"].fillna(X_train['Age'].mean(), inplace=True)\n",
    "X_val[\"Age\"].fillna(X_val['Age'].mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix - Training Set \n",
      "[[428  12]\n",
      " [ 17 255]]\n",
      "Confusion Matrix - Validation Set \n",
      "[[90 19]\n",
      " [33 37]]\n",
      "Accuracy Score - Training Set 0.959269662921\n",
      "Accuracy Score - Validation Set 0.709497206704\n"
     ]
    }
   ],
   "source": [
    "# Now, let's build this quick and dirty model using the RandomForestClassifier.\n",
    "# I'm going with 1000 estimators and setting the parallelization to match the no. of cores on my machine.\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=1000, n_jobs = -1)\n",
    "\n",
    "# I'm dropping the Passenger Id column, as it seems to be irrelevant. \n",
    "# But it might be an interesting observation to make in the future models. For now, I'm skipping it.\n",
    "\n",
    "features = ['Pclass', 'Age', 'SibSp', 'Parch', 'Fare']\n",
    "\n",
    "clf.fit(X_train[features], y_train)\n",
    "\n",
    "y_pred_train = clf.predict(X_train[features])\n",
    "y_pred_val = clf.predict(X_val[features])\n",
    "\n",
    "# Let's measure the performance of this model on training and validation data sets, \n",
    "# which can be later used for model comparisons without making submissions on Kaggle.\n",
    "\n",
    "print \"Confusion Matrix - Training Set \\n\", confusion_matrix(y_train, y_pred_train)\n",
    "print \"Confusion Matrix - Validation Set \\n\", confusion_matrix(y_val, y_pred_val)\n",
    "\n",
    "print \"Accuracy Score - Training Set\", accuracy_score(y_train, y_pred_train)\n",
    "print \"Accuracy Score - Validation Set\", accuracy_score(y_val, y_pred_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[535  14]\n",
      " [ 24 318]]\n",
      "0.957351290685\n"
     ]
    }
   ],
   "source": [
    "# Next, we'll do the predictions for the test data set,\n",
    "# but before that, I'm guessing rebuilding this model with the complete training data set would be more performant.\n",
    "\n",
    "clf.fit(X[features], y)\n",
    "y_pred = clf.predict(X[features])\n",
    "\n",
    "print confusion_matrix(y, y_pred)\n",
    "print accuracy_score(y, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Let's do the predictions for the test data set now\n",
    "X_test = pd.read_csv(\"test.csv\")\n",
    "\n",
    "dummy_sex = pd.get_dummies(X_test['Sex'], prefix='Sex')\n",
    "dummy_embarked = pd.get_dummies(X_test['Embarked'], prefix='Embarked')\n",
    "\n",
    "X_test = pd.concat([X_test, dummy_sex], axis = 1)\n",
    "X_test = pd.concat([X_test, dummy_embarked], axis = 1)\n",
    "X_test[\"Age\"].fillna(X_test['Age'].mean(), inplace=True)\n",
    "X_test[\"Fare\"].fillna(0, inplace=True)\n",
    "\n",
    "y_pred_test = clf.predict(X_test[features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# submission = pd.DataFrame({'PassengerId': X_test['PassengerId'], 'Survived': y_pred_test})\n",
    "# submission.to_csv(\"submission_1.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### I have submitted the above predictions and got a score of 0.60766 on Kaggle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, let's try to improvise this model by using the features - Sex and Embarked. \n",
    "# To do this, we need to encode these categorical columns into dummy variables\n",
    "\n",
    "X = pd.concat([X, pd.get_dummies(X['Sex'], prefix='Sex')], axis = 1)\n",
    "X_train = pd.concat([X_train, pd.get_dummies(X_train['Sex'], prefix='Sex')], axis = 1)\n",
    "X_val = pd.concat([X_val, pd.get_dummies(X_val['Sex'], prefix='Sex')], axis = 1)\n",
    "\n",
    "X = pd.concat([X, pd.get_dummies(X['Embarked'], prefix='Embarked')], axis = 1)\n",
    "X_train = pd.concat([X_train, pd.get_dummies(X_train['Embarked'], prefix='Embarked')], axis = 1)\n",
    "X_val = pd.concat([X_val, pd.get_dummies(X_val['Embarked'], prefix='Embarked')], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix - Training Set \n",
      "[[437   3]\n",
      " [  9 263]]\n",
      "Confusion Matrix - Validation Set \n",
      "[[97 12]\n",
      " [21 49]]\n",
      "Accuracy Score - Training Set 0.983146067416\n",
      "Accuracy Score - Validation Set 0.815642458101\n"
     ]
    }
   ],
   "source": [
    "# Now, let's use the new feature set to build and run the model\n",
    "features = ['Pclass', 'Age', 'Sex_male', 'Sex_female', 'SibSp', 'Parch', 'Fare', 'Embarked_C', 'Embarked_Q', 'Embarked_S']\n",
    "\n",
    "clf.fit(X_train[features], y_train)\n",
    "\n",
    "y_pred_train = clf.predict(X_train[features])\n",
    "y_pred_val = clf.predict(X_val[features])\n",
    "\n",
    "# Measure the performance of this model on training and validation data set.\n",
    "print \"Confusion Matrix - Training Set \\n\", confusion_matrix(y_train, y_pred_train)\n",
    "print \"Confusion Matrix - Validation Set \\n\", confusion_matrix(y_val, y_pred_val)\n",
    "\n",
    "print \"Accuracy Score - Training Set\", accuracy_score(y_train, y_pred_train)\n",
    "print \"Accuracy Score - Validation Set\", accuracy_score(y_val, y_pred_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at these performance measurements, this model certainly looks better than our first model. Let's go ahead and do the predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[544   5]\n",
      " [ 11 331]]\n",
      "0.982042648709\n"
     ]
    }
   ],
   "source": [
    "# Again, let's rebuild this model with the complete training set before running the predictions\n",
    "\n",
    "clf.fit(X[features], y)\n",
    "y_pred = clf.predict(X[features])\n",
    "\n",
    "print confusion_matrix(y, y_pred)\n",
    "print accuracy_score(y, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's do the predictions now\n",
    "X_test = pd.read_csv(\"test.csv\")\n",
    "\n",
    "dummy_sex = pd.get_dummies(X_test['Sex'], prefix='Sex')\n",
    "dummy_embarked = pd.get_dummies(X_test['Embarked'], prefix='Embarked')\n",
    "\n",
    "X_test = pd.concat([X_test, dummy_sex], axis = 1)\n",
    "X_test = pd.concat([X_test, dummy_embarked], axis = 1)\n",
    "X_test[\"Age\"].fillna(X_test['Age'].mean(), inplace=True)\n",
    "X_test[\"Fare\"].fillna(0, inplace=True)\n",
    "\n",
    "y_pred_test = clf.predict(X_test[features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "metadata": {},
   "outputs": [],
   "source": [
    "# submission = pd.DataFrame({'PassengerId': X_test['PassengerId'], 'Survived': y_pred_test})\n",
    "# submission.to_csv(\"submission_2.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### I have submitted the above predictions and got a score of 0.75598"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
